{"cells":[{"cell_type":"markdown","metadata":{"id":"XIyP_0r6zuVc"},"source":["# `transformers` meets `bitsandbytes` for democratzing Large Language Models (LLMs) through 4bit quantization\n","\n","QLora Training on Social Media Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuXIFTFapAMI","scrolled":true,"outputId":"74a77a53-2522-4691-e6c0-db26b7e733eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting git+https://github.com/stanfordnlp/pyreft.git\n","  Cloning https://github.com/stanfordnlp/pyreft.git to /tmp/pip-req-build-641gnwm1\n","  Running command git clone --filter=blob:none --quiet https://github.com/stanfordnlp/pyreft.git /tmp/pip-req-build-641gnwm1\n","  Resolved https://github.com/stanfordnlp/pyreft.git to commit b4c82d363494eee0560d74c1be2efc931f5f7045\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: accelerate>=0.29.1 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.30.0.dev0)\n","Requirement already satisfied: datasets>=2.18.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (2.18.0)\n","Requirement already satisfied: evaluate>=0.4.1 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.4.2)\n","Requirement already satisfied: fsspec>=2024.2.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (2024.2.0)\n","Requirement already satisfied: gcsfs>=2024.2.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (2024.2.0)\n","Requirement already satisfied: huggingface-hub>=0.20.3 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.20.3)\n","Requirement already satisfied: ipywidgets>=8.1.1 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (8.1.1)\n","Requirement already satisfied: jupyter in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (1.0.0)\n","Requirement already satisfied: matplotlib>=3.7.4 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (3.8.4)\n","Requirement already satisfied: numpy>=1.26.4 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (1.26.4)\n","Requirement already satisfied: plotnine>=0.12.4 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.13.5)\n","Requirement already satisfied: protobuf>=3.20.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (4.23.4)\n","Requirement already satisfied: pyvene>=0.1.1 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.1.1)\n","Requirement already satisfied: scikit-learn in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (1.3.0)\n","Requirement already satisfied: seaborn==0.12.2 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.12.2)\n","Requirement already satisfied: sentencepiece>=0.1.96 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.1.99)\n","Requirement already satisfied: torch>=2.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (2.1.1)\n","Requirement already satisfied: transformers>=4.39.3 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (4.41.0.dev0)\n","Requirement already satisfied: wandb in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (0.16.6)\n","Requirement already satisfied: ydata-profiling>=4.7.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pyreft==0.0.5) (4.7.0)\n","Requirement already satisfied: pandas>=0.25 in /home/paperspace/.local/lib/python3.11/site-packages (from seaborn==0.12.2->pyreft==0.0.5) (2.1.3)\n","Requirement already satisfied: packaging>=20.0 in /home/paperspace/.local/lib/python3.11/site-packages (from accelerate>=0.29.1->pyreft==0.0.5) (23.2)\n","Requirement already satisfied: psutil in /home/paperspace/.local/lib/python3.11/site-packages (from accelerate>=0.29.1->pyreft==0.0.5) (5.9.6)\n","Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=0.29.1->pyreft==0.0.5) (5.4.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /home/paperspace/.local/lib/python3.11/site-packages (from accelerate>=0.29.1->pyreft==0.0.5) (0.4.3)\n","Requirement already satisfied: filelock in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (14.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (0.3.7)\n","Requirement already satisfied: requests>=2.19.0 in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (4.66.1)\n","Requirement already satisfied: xxhash in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (3.4.1)\n","Requirement already satisfied: multiprocess in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (0.70.15)\n","Requirement already satisfied: aiohttp in /home/paperspace/.local/lib/python3.11/site-packages (from datasets>=2.18.0->pyreft==0.0.5) (3.9.0)\n","Requirement already satisfied: decorator>4.1.2 in /home/paperspace/.local/lib/python3.11/site-packages (from gcsfs>=2024.2.0->pyreft==0.0.5) (5.1.1)\n","Requirement already satisfied: google-auth>=1.2 in /home/paperspace/.local/lib/python3.11/site-packages (from gcsfs>=2024.2.0->pyreft==0.0.5) (2.29.0)\n","Requirement already satisfied: google-auth-oauthlib in /home/paperspace/.local/lib/python3.11/site-packages (from gcsfs>=2024.2.0->pyreft==0.0.5) (1.1.0)\n","Requirement already satisfied: google-cloud-storage in /home/paperspace/.local/lib/python3.11/site-packages (from gcsfs>=2024.2.0->pyreft==0.0.5) (2.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/paperspace/.local/lib/python3.11/site-packages (from huggingface-hub>=0.20.3->pyreft==0.0.5) (4.11.0)\n","Requirement already satisfied: comm>=0.1.3 in /home/paperspace/.local/lib/python3.11/site-packages (from ipywidgets>=8.1.1->pyreft==0.0.5) (0.2.0)\n","Requirement already satisfied: ipython>=6.1.0 in /home/paperspace/.local/lib/python3.11/site-packages (from ipywidgets>=8.1.1->pyreft==0.0.5) (8.17.2)\n","Requirement already satisfied: traitlets>=4.3.1 in /home/paperspace/.local/lib/python3.11/site-packages (from ipywidgets>=8.1.1->pyreft==0.0.5) (5.13.0)\n","Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/paperspace/.local/lib/python3.11/site-packages (from ipywidgets>=8.1.1->pyreft==0.0.5) (4.0.9)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/paperspace/.local/lib/python3.11/site-packages (from ipywidgets>=8.1.1->pyreft==0.0.5) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/paperspace/.local/lib/python3.11/site-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /home/paperspace/.local/lib/python3.11/site-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/paperspace/.local/lib/python3.11/site-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (4.45.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /home/paperspace/.local/lib/python3.11/site-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (1.4.5)\n","Requirement already satisfied: pillow>=8 in /home/paperspace/.local/lib/python3.11/site-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/paperspace/.local/lib/python3.11/site-packages (from matplotlib>=3.7.4->pyreft==0.0.5) (2.8.2)\n","Requirement already satisfied: mizani~=0.11.0 in /home/paperspace/.local/lib/python3.11/site-packages (from plotnine>=0.12.4->pyreft==0.0.5) (0.11.2)\n","Requirement already satisfied: scipy>=1.7.0 in /home/paperspace/.local/lib/python3.11/site-packages (from plotnine>=0.12.4->pyreft==0.0.5) (1.11.2)\n","Requirement already satisfied: statsmodels>=0.14.0 in /home/paperspace/.local/lib/python3.11/site-packages (from plotnine>=0.12.4->pyreft==0.0.5) (0.14.2)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sympy in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (1.12)\n","Requirement already satisfied: networkx in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=2.0.0->pyreft==0.0.5) (3.0.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /home/paperspace/.local/lib/python3.11/site-packages (from torch>=2.0.0->pyreft==0.0.5) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/paperspace/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pyreft==0.0.5) (12.3.101)\n","Requirement already satisfied: regex!=2019.12.17 in /home/paperspace/.local/lib/python3.11/site-packages (from transformers>=4.39.3->pyreft==0.0.5) (2023.10.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/paperspace/.local/lib/python3.11/site-packages (from transformers>=4.39.3->pyreft==0.0.5) (0.19.1)\n","Requirement already satisfied: pydantic>=2 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (2.7.1)\n","Requirement already satisfied: visions<0.7.7,>=0.7.5 in /home/paperspace/.local/lib/python3.11/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling>=4.7.0->pyreft==0.0.5) (0.7.6)\n","Requirement already satisfied: htmlmin==0.1.12 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (0.1.12)\n","Requirement already satisfied: phik<0.13,>=0.11.1 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (0.12.4)\n","Requirement already satisfied: multimethod<2,>=1.4 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (1.11.2)\n","Requirement already satisfied: typeguard<5,>=4.1.2 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (4.2.1)\n","Requirement already satisfied: imagehash==4.3.1 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (4.3.1)\n","Requirement already satisfied: wordcloud>=1.9.1 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (1.9.3)\n","Requirement already satisfied: dacite>=1.8 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (1.8.1)\n","Requirement already satisfied: numba<1,>=0.56.0 in /home/paperspace/.local/lib/python3.11/site-packages (from ydata-profiling>=4.7.0->pyreft==0.0.5) (0.59.1)\n","Requirement already satisfied: PyWavelets in /home/paperspace/.local/lib/python3.11/site-packages (from imagehash==4.3.1->ydata-profiling>=4.7.0->pyreft==0.0.5) (1.5.0)\n","Requirement already satisfied: notebook in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter->pyreft==0.0.5) (6.5.6)\n","Requirement already satisfied: qtconsole in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter->pyreft==0.0.5) (5.5.1)\n","Requirement already satisfied: jupyter-console in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter->pyreft==0.0.5) (6.6.3)\n","Requirement already satisfied: nbconvert in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter->pyreft==0.0.5) (7.11.0)\n","Requirement already satisfied: ipykernel in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter->pyreft==0.0.5) (6.27.0)\n","Requirement already satisfied: joblib>=1.1.1 in /home/paperspace/.local/lib/python3.11/site-packages (from scikit-learn->pyreft==0.0.5) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from scikit-learn->pyreft==0.0.5) (3.2.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb->pyreft==0.0.5) (8.0.3)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from wandb->pyreft==0.0.5) (3.1.40)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from wandb->pyreft==0.0.5) (1.36.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /home/paperspace/.local/lib/python3.11/site-packages (from wandb->pyreft==0.0.5) (0.4.0)\n","Requirement already satisfied: setproctitle in /home/paperspace/.local/lib/python3.11/site-packages (from wandb->pyreft==0.0.5) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb->pyreft==0.0.5) (59.6.0)\n","Requirement already satisfied: appdirs>=1.4.3 in /home/paperspace/.local/lib/python3.11/site-packages (from wandb->pyreft==0.0.5) (1.4.4)\n","Requirement already satisfied: attrs>=17.3.0 in /home/paperspace/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->pyreft==0.0.5) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/paperspace/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->pyreft==0.0.5) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/paperspace/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->pyreft==0.0.5) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/paperspace/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->pyreft==0.0.5) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/paperspace/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->pyreft==0.0.5) (1.3.1)\n","Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->pyreft==0.0.5) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /home/paperspace/.local/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->pyreft==0.0.5) (4.0.11)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs>=2024.2.0->pyreft==0.0.5) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs>=2024.2.0->pyreft==0.0.5) (0.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs>=2024.2.0->pyreft==0.0.5) (4.8)\n","Requirement already satisfied: jedi>=0.16 in /home/paperspace/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /home/paperspace/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (0.1.6)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/paperspace/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (3.0.41)\n","Requirement already satisfied: pygments>=2.4.0 in /home/paperspace/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (2.17.2)\n","Requirement already satisfied: stack-data in /home/paperspace/.local/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (0.6.3)\n","Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (4.8.0)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/paperspace/.local/lib/python3.11/site-packages (from numba<1,>=0.56.0->ydata-profiling>=4.7.0->pyreft==0.0.5) (0.42.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=0.25->seaborn==0.12.2->pyreft==0.0.5) (2022.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/paperspace/.local/lib/python3.11/site-packages (from pandas>=0.25->seaborn==0.12.2->pyreft==0.0.5) (2023.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /home/paperspace/.local/lib/python3.11/site-packages (from pydantic>=2->ydata-profiling>=4.7.0->pyreft==0.0.5) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /home/paperspace/.local/lib/python3.11/site-packages (from pydantic>=2->ydata-profiling>=4.7.0->pyreft==0.0.5) (2.18.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/paperspace/.local/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.18.0->pyreft==0.0.5) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.18.0->pyreft==0.0.5) (3.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/paperspace/.local/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.18.0->pyreft==0.0.5) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.18.0->pyreft==0.0.5) (2020.6.20)\n","Requirement already satisfied: patsy>=0.5.6 in /home/paperspace/.local/lib/python3.11/site-packages (from statsmodels>=0.14.0->plotnine>=0.12.4->pyreft==0.0.5) (0.5.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/paperspace/.local/lib/python3.11/site-packages (from google-auth-oauthlib->gcsfs>=2024.2.0->pyreft==0.0.5) (1.3.1)\n","Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /home/paperspace/.local/lib/python3.11/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft==0.0.5) (2.19.0)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /home/paperspace/.local/lib/python3.11/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft==0.0.5) (2.4.1)\n","Requirement already satisfied: google-resumable-media>=2.6.0 in /home/paperspace/.local/lib/python3.11/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft==0.0.5) (2.7.0)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/paperspace/.local/lib/python3.11/site-packages (from google-cloud-storage->gcsfs>=2024.2.0->pyreft==0.0.5) (1.5.0)\n","Requirement already satisfied: debugpy>=1.6.5 in /home/paperspace/.local/lib/python3.11/site-packages (from ipykernel->jupyter->pyreft==0.0.5) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /home/paperspace/.local/lib/python3.11/site-packages (from ipykernel->jupyter->pyreft==0.0.5) (7.4.9)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/paperspace/.local/lib/python3.11/site-packages (from ipykernel->jupyter->pyreft==0.0.5) (5.5.0)\n","Requirement already satisfied: nest-asyncio in /home/paperspace/.local/lib/python3.11/site-packages (from ipykernel->jupyter->pyreft==0.0.5) (1.5.8)\n","Requirement already satisfied: pyzmq>=20 in /home/paperspace/.local/lib/python3.11/site-packages (from ipykernel->jupyter->pyreft==0.0.5) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /home/paperspace/.local/lib/python3.11/site-packages (from ipykernel->jupyter->pyreft==0.0.5) (6.3.3)\n","Requirement already satisfied: beautifulsoup4 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (4.12.2)\n","Requirement already satisfied: bleach!=5.0.0 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (6.1.0)\n","Requirement already satisfied: defusedxml in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (0.2.2)\n","Requirement already satisfied: markupsafe>=2.0 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (2.1.3)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (0.9.0)\n","Requirement already satisfied: nbformat>=5.7 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (5.9.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (1.5.0)\n","Requirement already satisfied: tinycss2 in /home/paperspace/.local/lib/python3.11/site-packages (from nbconvert->jupyter->pyreft==0.0.5) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /home/paperspace/.local/lib/python3.11/site-packages (from notebook->jupyter->pyreft==0.0.5) (23.1.0)\n","Requirement already satisfied: ipython-genutils in /home/paperspace/.local/lib/python3.11/site-packages (from notebook->jupyter->pyreft==0.0.5) (0.2.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /home/paperspace/.local/lib/python3.11/site-packages (from notebook->jupyter->pyreft==0.0.5) (1.8.2)\n","Requirement already satisfied: terminado>=0.8.3 in /home/paperspace/.local/lib/python3.11/site-packages (from notebook->jupyter->pyreft==0.0.5) (0.18.0)\n","Requirement already satisfied: prometheus-client in /home/paperspace/.local/lib/python3.11/site-packages (from notebook->jupyter->pyreft==0.0.5) (0.9.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /home/paperspace/.local/lib/python3.11/site-packages (from notebook->jupyter->pyreft==0.0.5) (1.0.0)\n","Requirement already satisfied: qtpy>=2.4.0 in /home/paperspace/.local/lib/python3.11/site-packages (from qtconsole->jupyter->pyreft==0.0.5) (2.4.1)\n","Requirement already satisfied: mpmath>=0.19 in /home/paperspace/.local/lib/python3.11/site-packages (from sympy->torch>=2.0.0->pyreft==0.0.5) (1.3.0)\n","Requirement already satisfied: webencodings in /home/paperspace/.local/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter->pyreft==0.0.5) (0.5.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /home/paperspace/.local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->pyreft==0.0.5) (5.0.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/paperspace/.local/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.2.0->pyreft==0.0.5) (1.63.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/paperspace/.local/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.2.0->pyreft==0.0.5) (1.23.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/paperspace/.local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (0.8.3)\n","Requirement already satisfied: entrypoints in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->pyreft==0.0.5) (0.4)\n","Requirement already satisfied: platformdirs>=2.5 in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->pyreft==0.0.5) (4.0.0)\n","Requirement already satisfied: jupyter-server>=1.8 in /home/paperspace/.local/lib/python3.11/site-packages (from nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (2.11.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /home/paperspace/.local/lib/python3.11/site-packages (from nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (0.2.3)\n","Requirement already satisfied: fastjsonschema in /home/paperspace/.local/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->pyreft==0.0.5) (2.19.0)\n","Requirement already satisfied: jsonschema>=2.6 in /home/paperspace/.local/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->pyreft==0.0.5) (4.20.0)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wcwidth in /home/paperspace/.local/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (0.2.12)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.2.0->pyreft==0.0.5) (3.2.0)\n","Requirement already satisfied: ptyprocess in /usr/lib/python3/dist-packages (from terminado>=0.8.3->notebook->jupyter->pyreft==0.0.5) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /home/paperspace/.local/lib/python3.11/site-packages (from argon2-cffi->notebook->jupyter->pyreft==0.0.5) (21.2.0)\n","Requirement already satisfied: soupsieve>1.2 in /home/paperspace/.local/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter->pyreft==0.0.5) (2.5)\n","Requirement already satisfied: executing>=1.2.0 in /home/paperspace/.local/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /home/paperspace/.local/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (2.4.1)\n","Requirement already satisfied: pure-eval in /home/paperspace/.local/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.1.1->pyreft==0.0.5) (0.2.2)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter->pyreft==0.0.5) (2023.11.1)\n","Requirement already satisfied: referencing>=0.28.4 in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter->pyreft==0.0.5) (0.31.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter->pyreft==0.0.5) (0.13.1)\n","Requirement already satisfied: anyio>=3.1.0 in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (4.0.0)\n","Requirement already satisfied: jupyter-events>=0.9.0 in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (0.9.0)\n","Requirement already satisfied: jupyter-server-terminals in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (0.4.4)\n","Requirement already satisfied: overrides in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (7.4.0)\n","Requirement already satisfied: websocket-client in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (0.57.0)\n","Requirement already satisfied: cffi>=1.0.1 in /home/paperspace/.local/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->pyreft==0.0.5) (1.16.0)\n","Requirement already satisfied: sniffio>=1.1 in /home/paperspace/.local/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (1.3.0)\n","Requirement already satisfied: pycparser in /home/paperspace/.local/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->pyreft==0.0.5) (2.21)\n","Requirement already satisfied: python-json-logger>=2.0.4 in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (2.0.7)\n","Requirement already satisfied: rfc3339-validator in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (0.1.4)\n","Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/paperspace/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (0.1.1)\n","Requirement already satisfied: fqdn in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (1.5.1)\n","Requirement already satisfied: isoduration in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (20.11.0)\n","Requirement already satisfied: jsonpointer>1.13 in /usr/lib/python3/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (2.0)\n","Requirement already satisfied: uri-template in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (1.3.0)\n","Requirement already satisfied: webcolors>=1.11 in /home/paperspace/.local/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (1.13)\n","Requirement already satisfied: arrow>=0.15.0 in /home/paperspace/.local/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (1.3.0)\n","Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/paperspace/.local/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->pyreft==0.0.5) (2.8.19.14)\n"]}],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q datasets\n","!pip install git+https://github.com/stanfordnlp/pyreft.git"]},{"cell_type":"markdown","metadata":{"id":"MJ-5idQwzvg-"},"source":["load the model - GPT-neo-x-20B (Note that the model itself is around 40GB in half precision)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0Nl5mWL0k2T","scrolled":false,"outputId":"b4ed29a7-f16a-4c0a-b5e7-7cfa176f68ad","colab":{"referenced_widgets":["0f61d618587e48499a57f710f866a9d8","a627cbd289b044039b1aa7fb2425c273","5f1bece25bb3433695ff63e5d1de7994","7e89824b423d4d569756d126cd281f64","b8edd88fd5184bfd8bf9c0a3abb9bcdb","b74d94aa91aa413b84873efcd08a6064","3419970875ef4e7285488f0a7bcae9b5","333aadc4b4a14351a2ff556ff8e892af","d7fe3bb7e1504b429383678dc427acc0","2e7ae3b4b36141bc861d8702204954eb","9119b825c8e34ece908238b134be5d6a"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f61d618587e48499a57f710f866a9d8","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a627cbd289b044039b1aa7fb2425c273","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f1bece25bb3433695ff63e5d1de7994","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/457k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e89824b423d4d569756d126cd281f64","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8edd88fd5184bfd8bf9c0a3abb9bcdb","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b74d94aa91aa413b84873efcd08a6064","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3419970875ef4e7285488f0a7bcae9b5","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/60.4k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"333aadc4b4a14351a2ff556ff8e892af","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/46 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7fe3bb7e1504b429383678dc427acc0","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00046.safetensors:   0%|          | 0.00/926M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e7ae3b4b36141bc861d8702204954eb","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00046.safetensors:   0%|          | 0.00/910M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9119b825c8e34ece908238b134be5d6a","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00046.safetensors:   0%|          | 0.00/910M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","import transformers\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from pyreft import get_reft_model, ReftConfig, LoreftIntervention, ReftTrainerForCausalLM\n","\n","# Step 1: Load the base model and tokenizer\n","model_name = \"EleutherAI/gpt-neox-20B\"  # Replace with the desired model\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n"]},{"cell_type":"markdown","metadata":{"id":"FCc64bfnmd3j"},"source":["Load Dataset and Map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6f4z8EYmcJ6","outputId":"5c97d675-fc40-46f9-ca7f-d8ceb29d0d93","colab":{"referenced_widgets":["e77ed77fdcb847108fc8a5b1f7534129","e24f825c54244d0aa7fac013df8433db"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e77ed77fdcb847108fc8a5b1f7534129","version_major":2,"version_minor":0},"text/plain":["Resolving data files:   0%|          | 0/60 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e24f825c54244d0aa7fac013df8433db","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1253762 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m], text_target\u001b[38;5;241m=\u001b[39mexamples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m], truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    556\u001b[0m }\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_dataset.py:3105\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3101\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3102\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3103\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3104\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_dataset.py:3482\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3478\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3479\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3480\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3482\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3491\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_dataset.py:3361\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3360\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3361\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3363\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3364\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3365\u001b[0m     }\n","Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_function\u001b[39m(examples):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2859\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2858\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2859\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2861\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2945\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2941\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2942\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2943\u001b[0m         )\n\u001b[1;32m   2944\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2945\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2947\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2966\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2967\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2984\u001b[0m     )\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3127\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a list of sequences or a list of pairs of sequences.\u001b[39;00m\n\u001b[1;32m   3112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;124;03m        details in `encode_plus`).\u001b[39;00m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m-> 3127\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[1;32m   3137\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3138\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3153\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3154\u001b[0m )\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2764\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 2764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2766\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2767\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2768\u001b[0m     )\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2772\u001b[0m     truncation_strategy \u001b[38;5;241m!=\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE\n\u001b[1;32m   2773\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2776\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (max_length \u001b[38;5;241m%\u001b[39m pad_to_multiple_of \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2777\u001b[0m ):\n","\u001b[0;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."]}],"source":["from datasets import load_dataset\n","import datasets\n","\n","dataset1 = load_dataset('json', data_dir='/home/paperspace/trainingModel/modelDataset/ExtraDataProcessed', split='train')\n","dataset2 = load_dataset('json', data_dir='/home/paperspace/trainingModel/modelDataset/MastodonProcessed', split='train')\n","\n","data = datasets.concatenate_datasets([dataset1, dataset2])\n","\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"content\"], text_target=examples[\"content\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","data = data.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iDvPx9jQpKW"},"outputs":[],"source":["# Step 3: Set up the ReFT configuration\n","reft_config = ReftConfig(representations={\n","    \"layer\": 19,\n","    \"component\": \"block_output\",\n","    \"low_rank_dimension\": 4,\n","    \"intervention\": LoreftIntervention(embed_dim=model.config.hidden_size, low_rank_dimension=4)\n","})\n","\n","# Step 4: Get the ReFT model\n","reft_model = get_reft_model(model, reft_config, set_device=False)"]},{"cell_type":"markdown","metadata":{"id":"_0MOtwf3zdZp"},"source":["Run the cell below to run the training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jq0nX33BmfaC","outputId":"cf66626e-1887-4eac-8d43-952f0d0af806"},"outputs":[{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n"]},{"ename":"ValueError","evalue":"You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['labels']","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m      4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs_reft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m[],  \u001b[38;5;66;03m# Disable reporting to TensorBoard\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mreft_model,\n\u001b[1;32m     20\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     21\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     22\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:1876\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1874\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2187\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2184\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2186\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2187\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   2190\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/data/data_collator.py:45\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_call(features)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_call(features)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/data/data_collator.py:761\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtorch_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, examples: List[Union[List[\u001b[38;5;28mint\u001b[39m], Any, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;66;03m# Handle dict or lists with proper padding and conversion to tensor.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], Mapping):\n\u001b[0;32m--> 761\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    766\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: _torch_collate_batch(examples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer, pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_to_multiple_of)\n\u001b[1;32m    767\u001b[0m         }\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/data/data_collator.py:66\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     padded \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m warning_state\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3275\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3273\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[39;00m\n\u001b[1;32m   3274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[0;32m-> 3275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3278\u001b[0m     )\n\u001b[1;32m   3280\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m   3282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n","\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['labels']"]}],"source":["# Step 5: Set up the training arguments\n","training_args = transformers.TrainingArguments(\n","    output_dir=\"outputs_reft\",\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=8,\n","    warmup_steps=100,\n","    max_steps=500,\n","    learning_rate=1e-4,\n","    fp16=True,\n","    logging_steps=50\n",")\n","\n","# Step 6: Create the trainer\n","trainer = ReftTrainerForCausalLM(\n","    model=reft_model,\n","    args=training_args,\n","    train_dataset=data,\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",")\n","\n","# Step 7: Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p66mZk1RAlOR"},"outputs":[],"source":["model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n","model_to_save.save_pretrained(\"outputs_reft\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L2Hllu-bCuN6"},"outputs":[],"source":["reft_config = pyreft.ReftConfig.from_pretrained('outputs_reft')\n","model = pyreft.get_reft_model(model, reft_config)"]},{"cell_type":"markdown","metadata":{"id":"TxkvjRBjQpKX"},"source":["Model Question Input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1TiIH6vAlr_"},"outputs":[],"source":["text = \"Is bitcoin a good cryptocurrency?\"\n","device = \"cuda:0\"\n","\n","inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n","outputs = model.generate(**inputs, max_new_tokens=20)\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}